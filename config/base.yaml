# NRHOF bot - Base Configuration
# Shared settings across all environments
# Environment-specific overrides in config/envs/{env}.yaml
# Set NRHOF_ENV=dev|prod to switch environments (default: dev)

# Fonts configuration
fonts:
  directory: "assets/fonts"
  mono: "IBMPlexMono-Regular.ttf"
  mono_bold: "IBMPlexMono-SemiBoldItalic.ttf"
  sans: "Compadre-Extended.otf"
  sans_bold: "Compadre-Extended.otf"

# Render settings
render:
  backend: "pygame"          # pygame (current) | swift (future Metal renderer)
  resolution: [1280, 1024]
  fullscreen: false           # Run in fullscreen mode
  display: 0                 # 0=primary display, 1=secondary display
  fps_target: 60
  # Note: Colors, fonts, and visual styling now in styles/pipboy.yaml

# Audio settings
audio:
  sample_rate: 44100
  frame_size: 2048
  music_threshold: 0.01      # RMS threshold for music detection
  music_debounce: 0.5        # Seconds before state change
  poll_interval: 0.1         # Audio monitoring interval (100ms)

# Voice front-end (unified mic processing, VAD, wake word)
voice_front_end:
  enabled: true              # Enable voice front-end worker (replaces mic_listener, vad, wake_word workers)
  enable_vad: true           # Enable Cobra VAD for speech detection
  vad_threshold: 0.4         # Voice probability threshold (0.0 to 1.0) - lowered to prevent early cutoff
  vad_tail_ms: 800           # Tail silence for speech segment end detection
  speech_timeout_s: 4.0      # Max time to wait for speech after wake word
  min_post_speech_silence_ms: 800  # Minimum silence after speech before Rhino finalize
  rhino_finalize_timeout_ms: 8000  # Max time to wait for Rhino to finalize inference
  intent_cooldown_s: 2.0     # Cooldown window after intent resolution (prevents re-triggers during scene transitions)
  log_interval_s: 10         # How often to log stats
  update_interval_ms: 100    # How often to update audio level for HUD

  # Rhino NLU (deterministic intent recognition)
  rhino:
    enabled: true            # Enable Rhino for on-device intent recognition
    context_path: assets/voice/nrhof_en_mac_v3_0_0.rhn  # Path to .rhn context file
    debug_save_audio: false  # Save audio segments to /tmp for debugging (creates .wav files)

# Whisper ASR (fallback when Rhino fails to recognize intent)
whisper:
  enabled: true              # Enable Whisper for ASR fallback
  server_url: "http://127.0.0.1:9001"  # whisper.cpp server endpoint
  timeout: 5.0               # Request timeout in seconds

# LLM NLU (Ollama - intent classification and chat)
llm:
  enabled: true              # Enable LLM for intent classification
  server_url: "http://localhost:11434"  # Ollama server endpoint
  model: "llama3.1:8b"       # Model to use (llama3.1:8b or llama3.1:70b)
  timeout: 30.0              # Request timeout in seconds

# Mic listener (legacy - replaced by voice_front_end)
mic_listener:
  enabled: false             # Disabled (replaced by voice_front_end)
  frame_duration_ms: 32      # 512 samples @ 16kHz (matches voice_front_end)
  update_interval_ms: 100
  log_interval_s: 5
  enable_koala: true

# Recognition settings (placeholder for future)
recognizer:
  enabled: false
  cooldown: 5.0              # Seconds between recognition attempts
  confidence_threshold: 0.7   # Minimum confidence to accept result
  same_track_window: 30.0    # Seconds to suppress duplicate recognition

# Integrations
integrations:
  webflow:
    enabled: true
    sync_window: 300.0       # Don't sync same track within 5 minutes
    retry_backoff_max: 300   # Max backoff in seconds

# Localization
localization:
  language: "en"  # en (English) | jp (Japanese)

# Wake word detection (Picovoice Porcupine)
# API key loaded from PICOVOICE_ACCESS_KEY environment variable
wake_word:
  enabled: true  # Set to true when you have Picovoice access key in .env
  picovoice_access_key: "${PICOVOICE_ACCESS_KEY}"  # Loaded from .env
  keywords: ["picovoice"]  # Built-in keywords: jarvis, alexa, computer, etc.
  keyword_paths: []  # Custom .ppn files (e.g., "assets/wake_words/hey-nerd.ppn")
  sensitivity: 0.75  # 0.0 (least sensitive) to 1.0 (most sensitive)

# Voice Activity Detection (legacy WebRTC VAD - replaced by voice_front_end with Cobra)
vad:
  enabled: false             # Disabled (replaced by voice_front_end with Cobra VAD)
  sample_rate: 16000
  frame_duration_ms: 10
  aggressiveness: 2
  tail_ms: 700

# Voice control and streaming audio (reserved for future implementation)
voice:
  # Speech-to-text provider (future: whisper, deepgram, etc.)
  stt_provider: null
  stt_model: null

  # Text-to-speech provider (future: elevenlabs, openai, etc.)
  tts_provider: null
  tts_voice: null

  # Audio ducking (reduce background volume during voice interaction)
  ducking:
    enabled: false
    gain_db: -12.0  # Volume reduction in dB
    fade_duration_ms: 300  # Fade in/out duration

  # Acoustic echo cancellation (future)
  aec:
    enabled: false
    filter_length: 512  # AEC filter length in samples

  # Voice activity detection
  vad:
    enabled: false
    threshold: 0.5  # Voice activity threshold

# Spotify Integration (Primary music source)
spotify:
  enabled: true
  client_id: "${SPOTIFY_CLIENT_ID}"
  client_secret: "${SPOTIFY_CLIENT_SECRET}"
  redirect_uri: "http://127.0.0.1:8888/callback"
  cache_path: ".spotify_cache"  # OAuth token cache (gitignored)
  poll_interval_seconds: 2.0  # How often to check for track changes

# Sonos Integration (Secondary music source - local network)
sonos:
  enabled: true
  poll_interval_seconds: 2.0  # How often to check for track changes
  target_room: null  # null = dynamically follow any playing speaker, or set specific room speaker, or set specific room name room name (e.g., "Living Room"), null = auto-discover

# Source Manager (Music source arbitration)
source_manager:
  min_change_interval_seconds: 2.0  # Debounce track changes
  confidence_threshold: 0.6  # Minimum confidence for vinyl matches
  hysteresis_seconds: 5.0  # Stick to current source for this long

# Song Recognition (ACRCloud) - Only for vinyl/line-in mode
song_recognition:
  enabled: false  # Disabled - will use Spotify as primary source
  acrcloud:
    access_key: "${ACRCLOUD_ACCESS_KEY}"
    access_secret: "${ACRCLOUD_ACCESS_SECRET}"
    host: "${ACRCLOUD_HOST}"
  min_interval_seconds: 10
  audio_buffer_seconds: 8

# Feature flags
flags:
  use_prebaked_video: false
  use_live_math: true
  enable_recognition: false
  enable_webflow: false
  enable_voice: true
  offline_mode: false
  skip_intro: false  # Skip intro typewriter scene (for development)

# Note: Scene content (splash, intro, menu) now in content/ directory
# Note: Scene layouts now in layouts/ directory
# Note: Theme colors and fonts now in styles/ directory

# Visualizer settings
visualizers:
  spectrum_bars:
    bars: 32
    decay: 0.95

  waveform:
    num_waves: 3
    points: 100
    speed: 2.0
    freq_bands: [[20, 250], [250, 2000], [2000, 20000]]

  lissajous:
    a: 3
    b: 4
    delta: 1.5708
    trail: 50

# Logging
logging:
  level: "DEBUG"              # DEBUG, INFO, WARNING, ERROR
  file: "runtime/bot.log"
  max_size_mb: 10
  backup_count: 3
  structured: true           # JSON lines format
